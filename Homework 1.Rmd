---
title: "Homework 1"
author: "Elena Reynolds"
date: "August 11, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Probability Practice 

#Part A.
Here's a question a friend of mine was asked when he interviewed at Google.

Visitors to your website are asked to answer a single survey question before they get access to the content on the page. Among all of the users, there are two categories: Random Clicker (RC), and Truthful Clicker (TC). There are two possible answers to the survey: yes and no. Random clickers would click either one with equal probability. You are also giving the information that the expected fraction of random clickers is 0.3.

After a trial period, you get the following survey results: 65% said Yes and 35% said No.

What fraction of people who are truthful clickers answered yes? 5/7

Insert photo:

```{r}




```
#Part B.
Imagine a medical test for a disease with the following two attributes:

The sensitivity is about 0.993. That is, if someone has the disease, there is a probability of 0.993 that they will test positive.
The specificity is about 0.9999. This means that if someone doesn't have the disease, there is probability of 0.9999 that they will test negative.
In the general population, incidence of the disease is reasonably rare: about 0.0025% of all people have it (or 0.000025 as a decimal probability).

Suppose someone tests positive. What is the probability that they have the disease? In light of this calculation, do you envision any problems in implementing a universal testing policy for the disease?

Insert photo of math:


Answer: 
-Given someone tests positive, there is a 19.9% probability that they have the disease. In implementing a universal testing policy, people being tested should be made aware that there is only a 1 in 5 chance that they have the disease given their positive test. Those showing positive test results will have to go into further testing to confirm the disease state, otherwise they may be mistakenly treated for a disease they don't have. 


#Exploratory Analysis: Green Buildings

```{r}

```



##Bootstrapping


#Portfolio 1: Equal split across given ETFs
```{r}

set.seed(123)
library(foreach)
library(quantmod)
library(mosaic)

assets = c("SPY","TLT","LQD","EEM","VNQ")
prices = getSymbols(assets, from = "2006-01-01")

for(ticker in assets) {
  expr = paste0(ticker, "a = adjustOHLC(", ticker, ")")
  eval(parse(text=expr))
}

par(mfrow=c(3,2))
plot(ClCl(SPYa))
hist(ClCl(SPYa), breaks=50) 
plot(ClCl(TLTa))
hist(ClCl(TLTa), breaks=50)
plot(ClCl(LQDa))
hist(ClCl(LQDa), breaks=50)
plot(ClCl(EEMa))
hist(ClCl(EEMa), breaks=50)
plot(ClCl(VNQa))
hist(ClCl(VNQa), breaks=50)

# Combine all the returns in a matrix
all_returns = cbind(	
  ClCl(SPYa),
  ClCl(TLTa),
  ClCl(LQDa),
  ClCl(EEMa),
  ClCl(VNQa)
)
all_returns = as.matrix(na.omit(all_returns))

# Simulate a random day
return.today = resample(all_returns, 1, orig.ids=FALSE)

# Looping over 4 trading weeks (n_days = 20)
initial_wealth = 100000
sim1 = foreach(i=1:5000, .combine='rbind') %do% {
  total_wealth = initial_wealth
  weights = c(0.2, 0.2, 0.2, 0.2, 0.2)
  holdings = weights * total_wealth
  n_days = 20
  wealthtracker = rep(0, n_days)
  for(today in 1:n_days) {
    return.today = resample(all_returns, 1, orig.ids=FALSE)
    holdings = holdings*(1 + return.today)
    total_wealth = sum(holdings)
    wealthtracker[today] = total_wealth
    holdings = weights * total_wealth
  }
  wealthtracker
}

par(mfrow=c(2,1))
hist(sim1[,n_days], 25)

# Profit/loss
mean(sim1[,n_days])
hist(sim1[,n_days]- initial_wealth, breaks=30)

# Calculate 5% value at risk  
quantile(sim1[,n_days], 0.05) - initial_wealth    
```

# Portfolio 2: Safe ETFs
```{r}

set.seed(123)
library(foreach)
library(quantmod)
library(mosaic)

safe = c("SPHD","EFAV","AGG") 
safeprices = getSymbols(safe, from = "2006-01-01")

for(ticker in safe) {
  expr = paste0(ticker, "a = adjustOHLC(", ticker, ")")
  eval(parse(text=expr))
}

par(mfrow=c(3,2))
plot(ClCl(SPHDa))
hist(ClCl(SPHDa), breaks=50) 
plot(ClCl(EFAVa))
hist(ClCl(EFAVa), breaks=50)
plot(ClCl(AGGa))
hist(ClCl(AGGa), breaks=50)

# Combine all the returns in a matrix
all_returns = cbind(	
  ClCl(SPHDa),
  ClCl(EFAVa),
  ClCl(AGGa)
)
all_returns = as.matrix(na.omit(all_returns))

# Simulate a random day
return.today = resample(all_returns, 1, orig.ids=FALSE)

# Loop over 4 trading weeks
initial_wealth = 100000
sim1 = foreach(i=1:5000, .combine='rbind') %do% {
  total_wealth = initial_wealth
  weights = c(1/3, 1/3, 1/3)
  holdings = weights * total_wealth
  n_days = 20
  wealthtracker = rep(0, n_days)
  for(today in 1:n_days) {
    return.today = resample(all_returns, 1, orig.ids=FALSE)
    holdings = holdings*(1 + return.today)
    total_wealth = sum(holdings)
    wealthtracker[today] = total_wealth
    holdings = weights * total_wealth
  }
  wealthtracker
}

par(mfrow=c(2,1))
hist(sim1[,n_days], 25)

# Profit/loss
mean(sim1[,n_days])
hist(sim1[,n_days]- initial_wealth, breaks=30)

# Calculate 5% value at risk 
quantile(sim1[,n_days], 0.05) - initial_wealth 
```

#Portfolio 3: Risky ETFs
```{r}
set.seed(123)
library(foreach)
library(quantmod)
library(mosaic)

risky = c("DUST","UVXY")
riskyprices = getSymbols(risky, from = "2006-01-01")

for(ticker in risky) {
  expr = paste0(ticker, "a = adjustOHLC(", ticker, ")")
  eval(parse(text=expr))
}

par(mfrow=c(3,2))
plot(ClCl(DUSTa))
hist(ClCl(DUSTa), breaks=50) 
plot(ClCl(UVXYa))
hist(ClCl(UVXYa), breaks=50)

# Combine all the returns in a matrix
all_returns = cbind(	
  ClCl(DUSTa),
  ClCl(UVXYa)
)
all_returns = as.matrix(na.omit(all_returns))

# Simulate a random day
return.today = resample(all_returns, 1, orig.ids=FALSE)

# Loop over 4 trading weeks:
initial_wealth = 100000
sim1 = foreach(i=1:5000, .combine='rbind') %do% {
  total_wealth = initial_wealth
  weights = c(0.5, 0.5)
  holdings = weights * total_wealth
  n_days = 20
  wealthtracker = rep(0, n_days)
  for(today in 1:n_days) {
    return.today = resample(all_returns, 1, orig.ids=FALSE)
    holdings = holdings + holdings*return.today
    total_wealth = sum(holdings)
    wealthtracker[today] = total_wealth
    holdings = weights * total_wealth
  }
  wealthtracker
}

par(mfrow=c(2,1))
hist(sim1[,n_days], 25)

# Profit/loss
mean(sim1[,n_days])
hist(sim1[,n_days]- initial_wealth, breaks=30)

# Calculate 5% value at risk 
quantile(sim1[,n_days], 0.05) - initial_wealth 

```
# Summary

Report results and compare histograms
Show final histograms for each portfolio and describe differences

##Market Segmentation

```{r}

library(ggplot2)
library(LICORS)  
library(foreach)
library(mosaic)

MarketData = read.csv('~/Documents/Github/STA380/data/social_marketing.csv', header=TRUE,row.names=1)
summary(MarketData)

X = MarketData/rowSums(MarketData)

# Using kmeans++ initialization

chRange = c()
wRange = c()

for (k in 2:10){
  clustk = assign(paste("clust",k, sep=""), kmeanspp(X, k, nstart=25))
  n = nrow(X)
  w = assign(paste("w",k, sep=""), clustk$tot.withinss)
  wRange = rbind(wRange, w)
  b = assign(paste("b",k, sep=""), clustk$betweenss)
  ch = assign(paste("ch",k, sep=""), (b/(k-1))/(w/(n-k)))
  chNew = ch
  chRange = rbind(chRange, chNew)
}

kRange = 2:10
plot(kRange, wRange)

chRange # max at k=2

```

```{r}

library(ggplot2)

MarketData = read.csv("~/Documents/Github/STA380/data/social_marketing.csv", header=TRUE,row.names=1)

# Normalize phrase counts to phrase frequencies
Z = MarketData/rowSums(MarketData)

# PCA
pc2 = prcomp(Z, scale=TRUE)
loadings = pc2$rotation
scores = pc2$x

qplot(scores[,1], scores[,2], xlab='Component 1', ylab='Component 2')

# The top words associated with each component
o1 = order(loadings[,1], decreasing=TRUE)
print("Most common tweet topics for users high in PC1:")
colnames(Z)[head(o1,6)]
print("Least common tweet topics for users high in PC1:")
colnames(Z)[tail(o1,6)]

o2 = order(loadings[,2], decreasing=TRUE)
print("Most common tweet topics for users high in PC2:")
colnames(Z)[head(o2,6)]
print("Least common tweet topics for users high in PC2:")
colnames(Z)[tail(o2,6)]


summary(pc2)
plot(pc2)
biplot(pc2)

```

